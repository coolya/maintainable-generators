{
    "docs": [
        {
            "location": "/",
            "text": "Towards Maintainable Generators\n\n\nThis website aims to provide a set of best practices for maintainable generators and a set of rules when to apply them. We do not explain the very basics of writing MPS generators so it's audience is clearly for people with experience in writing generators in MPS and it mostly covers advanced patterns and concepts.\n\n\nIntroduction\n\n\nAs any software generators can get complex and hard to maintain therefore it is important to write them in a way that makes them easy to maintain. Over the past years we have gathered quite a lot experience in writing theses generators. This website tries the provide a set of best practices and rules when theses practices might get applied. It's not meant as a fixed set of rules that should be blindly followed but as guidelines. We will discuss the tradeoffs and aspects to consider extensively. \n\n\nMaintainability\n\n\nWhat does maintainability mean in this context? On the one hand it is about the ability to change/delete/rewrite parts of the generator chain without affecting parts prior or later in the chain. On the other hand it's about writing readable generators which can easily be understood and reasoned \n\n\nState\n\n\nThis website is currently in development and has not undergone any copy editing or review. You might find typos and the style of writing might significantly vary from section to section. \n\n\nLicense\n\n\nThis website is published under the \nCreative Commons Attribution Share Alike 4.0 \n license.",
            "title": "Home"
        },
        {
            "location": "/#towards-maintainable-generators",
            "text": "This website aims to provide a set of best practices for maintainable generators and a set of rules when to apply them. We do not explain the very basics of writing MPS generators so it's audience is clearly for people with experience in writing generators in MPS and it mostly covers advanced patterns and concepts.",
            "title": "Towards Maintainable Generators"
        },
        {
            "location": "/#introduction",
            "text": "As any software generators can get complex and hard to maintain therefore it is important to write them in a way that makes them easy to maintain. Over the past years we have gathered quite a lot experience in writing theses generators. This website tries the provide a set of best practices and rules when theses practices might get applied. It's not meant as a fixed set of rules that should be blindly followed but as guidelines. We will discuss the tradeoffs and aspects to consider extensively.",
            "title": "Introduction"
        },
        {
            "location": "/#maintainability",
            "text": "What does maintainability mean in this context? On the one hand it is about the ability to change/delete/rewrite parts of the generator chain without affecting parts prior or later in the chain. On the other hand it's about writing readable generators which can easily be understood and reasoned",
            "title": "Maintainability"
        },
        {
            "location": "/#state",
            "text": "This website is currently in development and has not undergone any copy editing or review. You might find typos and the style of writing might significantly vary from section to section.",
            "title": "State"
        },
        {
            "location": "/#license",
            "text": "This website is published under the  Creative Commons Attribution Share Alike 4.0   license.",
            "title": "License"
        },
        {
            "location": "/Best Practices/",
            "text": "Best Practices\n\n\nDetecting Tests\n\n\nIn some cases generators should not transform node when they are used in tests as some of their assumptions about the structure of their input might not hold in tests. Tests often test nodes in isolation which doesn't work well with more complex generators that depend on some context.\n\n\nUse the \nIsInTestsExpression\n from the \ncom.mbeddr.mpsutil.blutil.genUtil\n language, which is part of the MPS-extensions:\n\n\nis applicable:\n    (genContext) -> boolean {\n        !is-in-tests;\n    }\n\n\n\n\nOr alternatively:\n\n\n--- is applicable ---\n(genContext)->boolean {\n  !genContext.originalModel.nodes(<all>).any({~it => it.concept.getLanguage().getQualifiedName().startsWith(\"jetbrains.mps.lang.test\"); });\n}\n\n\n\n\nIf you use the later it might make sense to move this code into a helper class and use it that in the various places of your code bases.\n\n\nPreprocessing\n\n\nIn scenarios where the structure of the input model is significantly different form the output structure it is often handy to use preprocessing scripts written in Java rather than reduction or weaving rules. Another sometimes useful benefit is that debugging Java code can be easier than the declarative and interpreted rules of the generator. \n\n\nAn example where preprocessing can make a lot of sense is inout collection for generation. If the generation target is for instance a XML file with a specific structure but the input model allows the user to freely place these elements preprocessing can collect all these contents and place them under a single node with a structure closer to the one of output. \n\n\nIn addition to using preprocessing for to change the structure of the input it is also handy to have intermediate language who's sole purpose is to ease generation. These languages often contain concepts that user does not need to specify explicitly in the input because they can be derived from the input. But during generation it often simplifies the generators if these elements are explicitly in the model because they can be generated by simple means of reduction rules. An example for this would be a generator that generates serialisation logic for data structures but could derive the data types for certain input automatically (e.g. boolean). The actual generator to produce the serialisation logic is much simpler to write when these data types are explicitly in the model. In this case the preprocessing would add these information.\n\n\nPreprocessing comes at a cost, as it's not as declarative as the generator language tracing has to be done manually via the \nTracingUtil\ns \nfillOriginalNode\n. Also registering inputs and outputs to mapping label needs to be done explicitly via: \ngenContext.label input to output as myLabel;\n. The generator is also not able to execute anything concurrently while a script is used. The usage of preprocessing scripts that heavily modify the model should be kept to a minimum. \n\n\nError Handling\n\n\nWhen reporting errors during generation the natural thing to use is exceptions as most of the code that is written in MPS generators is Java. But doing so has some disadvantages. \n\n\n\n\nIt stops generation immediately. The user only get's single error message if there are multiple errors during generator the user can only fix the first, then has to regenerated, get the next error and start over. This can be a very frustrating process.\n\n\nThere is no way to point the user to the input that caused the error. The exception will contain a link to the rule that cause it but there is not additional information useful for the user to debug. If transient models are turned on the user might be able to see the intermediate state which caused the error but it's often hard to guess from the which node in the original model caused it.\n\n\n\n\nIt is much better do something like this:\n\n\ngenContext.show error \"something went wrong\" -> genContext.get original copied input for (node)\n\n\n\n\nThis will stop generation after the current generation phase is complete. No other generators will execute afterwards, but it will collect all errors from the currently executed generator. It also allows to specify a node where the user is taken to when the messages is clicked. Together with the \ngenContext.get original copied input for (node)\n pattern it takes the user directly to the input in the original model. \n\n\nCopy and Reduce\n\n\nWhen generating output from a list of items or a single child node the first idea is often to use a \n$LOOP$\n macro or to do the transformation \nin place\n. While this looks easy in the first place it also limits extensibility. It is often much better to avoid this kind of pattern and use a combination for \n$COPY_SRC$\n/\n$COPY_SRCL$\n and a reduction rule for the concept. This allows extensions to contribute their own reduction rules for their concepts. Incase a \n$LOOP$\n macro would be used the only option to extend the generator would be to essentially copy the complete mapping and have the generator run before the one of the extended language is invoked. \n\n\nHere is an example from the mpsutil codebase: \n\n\nnew AfterExtension(\"$wizId\", \"$stepId\", new arraylist<AbstractWizardStepEx>{$LOOP$new ->$dummy_step()})\n\n\n\n\nIt assumes that all elements of the \narraylist\n are created by invoking a constructor of a class. If somebody wants to extend this behaviour and wants to include a singleton object into the list it's impossible. The code has been rewritten to:\n\n\nnew AfterExtension(\"$wizId\", \"$stepId\", new arraylist<AbstractWizardStepEx>{$COPY_SRCL$new dummy_step()})\n\n// and a reduction rule for the steps\n\nconcept Step       --> <T  new ->$dummy_step()  T> \n\ninheritors true                                     \ncondition <always>                                  \n\n\n\n\n\nAnother pattern to avoid this limitation is to use a \n$LOOP$\n macro but delegate the actual reduction into a template switch by calling it with a. \n$SWITCH$\n macro:\n\n\nnew ConceptEvaluatorBase(concept/->$ConceptEvaluator/, $true, $LOOP$$SWITCH$ populateConstraintconstraints) { \n\n\n\n\nPrefer Switches over Ifs\n\n\nIn cases where the generator should produce output based on a condition the common macro to use is usually the \n$IF$\n macro. There is nothing wrong with this per se but in cases where this condition is based on a model element other than a boolean property it is usually a smell that it should be replaced with a template switch. \n\n\nThe following example is from the mebddr codebase.\n\n\n$IF$return $COPY_SRC$null; / \n$ELSE$<T  $COPY_SRCL$return;  T>\n\n--- inspector --- \nconditional branch                                                                                                    \n\ncomment : <none>                                                                                                      \nmapping label : <no label>                                                                                            \ncondition : (genContext, node, operationContext)->boolean { \n  node.evaluator.isInstanceOf(ConceptEvaluatorInline); \n}\nalternative : <T  $COPY_SRCL$return;  T>                                                                              \n\n\n\n\nThe code essentially checks what kind of concept is in the \nevaluator\n child role and then changes the way in which it generates the code. It handles the two cases that were assumed in the original language perfectly well, but in case we want to introduce a custom \nEvaluator\n it would fail. \n\n\nis better rewritten like this:\n\n\n\n// replacment for the $IF$\n\n$SWITCH$ evaluatorImplementationreturn null;\n\n--- inspector ---\n\nswitch templates by input node                                                  \n\ncomment : <none>                                                                \nmapping label : <no label>                                                      \nuse input : (genContext, node, operationContext)->node<> { \n  node.evaluator; \n}\n\ntemplate switch : evaluatorImplementation                                       \n\n// the template switch\n\ntemplate switch evaluatorImplementation extends <none>                  \n\nparameters                                                              \n<< ... >>                                                               \n\n  null-input message: <none>                                            \n\n  cases:                                                                \n\n     concept ConceptEvaluatorInline --> <T  return $COPY_SRC$null;  T> \n\n     inheritors true                                                    \n     condition <always>                                                 \n     concept ConceptEvaluatorBody --> <T  $COPY_SRCL$return;  T> \n\n     inheritors true                                                    \n     condition <always>                                                 \n\n\n  default: DISMISS TOP RULE error : can not handle evaluator            \n\n\n\n\n\n\nNote that the external template switch is extensible from other generators. By simply defining a extends relationship: \ntemplate switch mySwitch extends evaluatorImplementation\n. This will contribute the additional cases each time the original switch is invoked. \n\n\nIn addition the original template switch, if it doesn't have a default case, wants to print an error message. Because otherwise the template switch invocation is replaced with node that has the \n$SWITCH$\n macro attached. This is done via a default rule that looks like this:\n\n\ndefault: DISMISS TOP RULE error : can not handle evaluator\n\n\n\n\nPredefined Generator Plans\n\n\nIn some cases defining a static generation plan can be very useful and simplify the view on which generators are engaged at which point during the generation. Though this is mostly the last option one want to take. At the moment the extensibility story for predefined generator plans is pretty limited compared to the dynamic approach with priorities. Currently you can only contribute generators to the predefined plan via extension dependency to a generator that is involved in the generation plan this generator is the executed in the same step as the extended generator. It can also cause problems in conjunction with node/editor tests. If a DevKit with a generation plan and this DevKit is used in tests, this can cause that MPS would not consider the generators of the test language. As mentioned above this is a solution that currently doesn't widely apply especially not if your languages are meant to be extended. But in some contexts where extensibility is not the main concern or even undesired using predefined generation plans can help.",
            "title": "Best Practices"
        },
        {
            "location": "/Best Practices/#best-practices",
            "text": "",
            "title": "Best Practices"
        },
        {
            "location": "/Best Practices/#detecting-tests",
            "text": "In some cases generators should not transform node when they are used in tests as some of their assumptions about the structure of their input might not hold in tests. Tests often test nodes in isolation which doesn't work well with more complex generators that depend on some context.  Use the  IsInTestsExpression  from the  com.mbeddr.mpsutil.blutil.genUtil  language, which is part of the MPS-extensions:  is applicable:\n    (genContext) -> boolean {\n        !is-in-tests;\n    }  Or alternatively:  --- is applicable ---\n(genContext)->boolean {\n  !genContext.originalModel.nodes(<all>).any({~it => it.concept.getLanguage().getQualifiedName().startsWith(\"jetbrains.mps.lang.test\"); });\n}  If you use the later it might make sense to move this code into a helper class and use it that in the various places of your code bases.",
            "title": "Detecting Tests"
        },
        {
            "location": "/Best Practices/#preprocessing",
            "text": "In scenarios where the structure of the input model is significantly different form the output structure it is often handy to use preprocessing scripts written in Java rather than reduction or weaving rules. Another sometimes useful benefit is that debugging Java code can be easier than the declarative and interpreted rules of the generator.   An example where preprocessing can make a lot of sense is inout collection for generation. If the generation target is for instance a XML file with a specific structure but the input model allows the user to freely place these elements preprocessing can collect all these contents and place them under a single node with a structure closer to the one of output.   In addition to using preprocessing for to change the structure of the input it is also handy to have intermediate language who's sole purpose is to ease generation. These languages often contain concepts that user does not need to specify explicitly in the input because they can be derived from the input. But during generation it often simplifies the generators if these elements are explicitly in the model because they can be generated by simple means of reduction rules. An example for this would be a generator that generates serialisation logic for data structures but could derive the data types for certain input automatically (e.g. boolean). The actual generator to produce the serialisation logic is much simpler to write when these data types are explicitly in the model. In this case the preprocessing would add these information.  Preprocessing comes at a cost, as it's not as declarative as the generator language tracing has to be done manually via the  TracingUtil s  fillOriginalNode . Also registering inputs and outputs to mapping label needs to be done explicitly via:  genContext.label input to output as myLabel; . The generator is also not able to execute anything concurrently while a script is used. The usage of preprocessing scripts that heavily modify the model should be kept to a minimum.",
            "title": "Preprocessing"
        },
        {
            "location": "/Best Practices/#error-handling",
            "text": "When reporting errors during generation the natural thing to use is exceptions as most of the code that is written in MPS generators is Java. But doing so has some disadvantages.    It stops generation immediately. The user only get's single error message if there are multiple errors during generator the user can only fix the first, then has to regenerated, get the next error and start over. This can be a very frustrating process.  There is no way to point the user to the input that caused the error. The exception will contain a link to the rule that cause it but there is not additional information useful for the user to debug. If transient models are turned on the user might be able to see the intermediate state which caused the error but it's often hard to guess from the which node in the original model caused it.   It is much better do something like this:  genContext.show error \"something went wrong\" -> genContext.get original copied input for (node)  This will stop generation after the current generation phase is complete. No other generators will execute afterwards, but it will collect all errors from the currently executed generator. It also allows to specify a node where the user is taken to when the messages is clicked. Together with the  genContext.get original copied input for (node)  pattern it takes the user directly to the input in the original model.",
            "title": "Error Handling"
        },
        {
            "location": "/Best Practices/#copy-and-reduce",
            "text": "When generating output from a list of items or a single child node the first idea is often to use a  $LOOP$  macro or to do the transformation  in place . While this looks easy in the first place it also limits extensibility. It is often much better to avoid this kind of pattern and use a combination for  $COPY_SRC$ / $COPY_SRCL$  and a reduction rule for the concept. This allows extensions to contribute their own reduction rules for their concepts. Incase a  $LOOP$  macro would be used the only option to extend the generator would be to essentially copy the complete mapping and have the generator run before the one of the extended language is invoked.   Here is an example from the mpsutil codebase:   new AfterExtension(\"$wizId\", \"$stepId\", new arraylist<AbstractWizardStepEx>{$LOOP$new ->$dummy_step()})  It assumes that all elements of the  arraylist  are created by invoking a constructor of a class. If somebody wants to extend this behaviour and wants to include a singleton object into the list it's impossible. The code has been rewritten to:  new AfterExtension(\"$wizId\", \"$stepId\", new arraylist<AbstractWizardStepEx>{$COPY_SRCL$new dummy_step()})\n\n// and a reduction rule for the steps\n\nconcept Step       --> <T  new ->$dummy_step()  T> \n\ninheritors true                                     \ncondition <always>                                    Another pattern to avoid this limitation is to use a  $LOOP$  macro but delegate the actual reduction into a template switch by calling it with a.  $SWITCH$  macro:  new ConceptEvaluatorBase(concept/->$ConceptEvaluator/, $true, $LOOP$$SWITCH$ populateConstraintconstraints) {",
            "title": "Copy and Reduce"
        },
        {
            "location": "/Best Practices/#prefer-switches-over-ifs",
            "text": "In cases where the generator should produce output based on a condition the common macro to use is usually the  $IF$  macro. There is nothing wrong with this per se but in cases where this condition is based on a model element other than a boolean property it is usually a smell that it should be replaced with a template switch.   The following example is from the mebddr codebase.  $IF$return $COPY_SRC$null; / \n$ELSE$<T  $COPY_SRCL$return;  T>\n\n--- inspector --- \nconditional branch                                                                                                    \n\ncomment : <none>                                                                                                      \nmapping label : <no label>                                                                                            \ncondition : (genContext, node, operationContext)->boolean { \n  node.evaluator.isInstanceOf(ConceptEvaluatorInline); \n}\nalternative : <T  $COPY_SRCL$return;  T>                                                                                The code essentially checks what kind of concept is in the  evaluator  child role and then changes the way in which it generates the code. It handles the two cases that were assumed in the original language perfectly well, but in case we want to introduce a custom  Evaluator  it would fail.   is better rewritten like this:  \n// replacment for the $IF$\n\n$SWITCH$ evaluatorImplementationreturn null;\n\n--- inspector ---\n\nswitch templates by input node                                                  \n\ncomment : <none>                                                                \nmapping label : <no label>                                                      \nuse input : (genContext, node, operationContext)->node<> { \n  node.evaluator; \n}\n\ntemplate switch : evaluatorImplementation                                       \n\n// the template switch\n\ntemplate switch evaluatorImplementation extends <none>                  \n\nparameters                                                              \n<< ... >>                                                               \n\n  null-input message: <none>                                            \n\n  cases:                                                                \n\n     concept ConceptEvaluatorInline --> <T  return $COPY_SRC$null;  T> \n\n     inheritors true                                                    \n     condition <always>                                                 \n     concept ConceptEvaluatorBody --> <T  $COPY_SRCL$return;  T> \n\n     inheritors true                                                    \n     condition <always>                                                 \n\n\n  default: DISMISS TOP RULE error : can not handle evaluator              Note that the external template switch is extensible from other generators. By simply defining a extends relationship:  template switch mySwitch extends evaluatorImplementation . This will contribute the additional cases each time the original switch is invoked.   In addition the original template switch, if it doesn't have a default case, wants to print an error message. Because otherwise the template switch invocation is replaced with node that has the  $SWITCH$  macro attached. This is done via a default rule that looks like this:  default: DISMISS TOP RULE error : can not handle evaluator",
            "title": "Prefer Switches over Ifs"
        },
        {
            "location": "/Best Practices/#predefined-generator-plans",
            "text": "In some cases defining a static generation plan can be very useful and simplify the view on which generators are engaged at which point during the generation. Though this is mostly the last option one want to take. At the moment the extensibility story for predefined generator plans is pretty limited compared to the dynamic approach with priorities. Currently you can only contribute generators to the predefined plan via extension dependency to a generator that is involved in the generation plan this generator is the executed in the same step as the extended generator. It can also cause problems in conjunction with node/editor tests. If a DevKit with a generation plan and this DevKit is used in tests, this can cause that MPS would not consider the generators of the test language. As mentioned above this is a solution that currently doesn't widely apply especially not if your languages are meant to be extended. But in some contexts where extensibility is not the main concern or even undesired using predefined generation plans can help.",
            "title": "Predefined Generator Plans"
        },
        {
            "location": "/Complex/",
            "text": "Complex Multistage Generators\n\n\nWhen writing large sets of generators and languages that build on top of each other it can be a challenge to understand what is going on during generation. Especially defining generator priorities to order them correctly can get messy quickly. If not taken care of it can happen that a lot of cross generator dependencies are introduces just for the sake of making sure generators are executed in the correct order. A pattern to counter this is to define logical checkpoint/barriers (not to be mistaken with the checkpoints you can define in a generation plan in MPS) in your generator priorities. Priorities are the assigned relative to this barriers. The barriers represent level of abstraction, If a generator requires a certain level of abstraction as input its priorities are defined according to that. It is important a singe generator is picked for each of these barriers to have single point where these dependencies are relative to. This makes debugging much easier. We will use an example from mbeddr below to illustrate this.\n\n\nMbeddr Example\n\n\nWhile mbeddr itself uses over 30 generators in total their priorities are in most cases easy to unterstand. Most of the generators are pretty isolated from the point of view and most of them only define that they need to be run before the the \nmodules.gen\n generator. In this example we will look at 3 logical stages of mbeddr all of them on different layers of abstraction.  We will start explaining them from the bottom to the top.\n\n\n \n\n\nmbeddr.modules.gen layer\n\n\nThis is the lowest layer of abstractions it assumes that the input is mbeddr C99 representation. This input is basically a simplified version C99 without headers and with some other minor adaptions. This generator transforms its input into \nreal\n C99 code with \n.c\n and \n.h\n files. If language extension provides a higher abstraction than this then it defines its generator priorities  relative to this generator. One example here is the \nmbeddr.unittest\n language. \n\n\nThe middle layer\n\n\nThis layer contains all sorts of higher level abstractions than C. They are all independent from each other but at some point they need to generate down to mbeddr C. This needs to happen before the \nmodules.gen\n generator is executed because it assumes that the input is C. All of the languages define their priority relative the \nmodules.gen\n generator. Debugging if the order is correct is easy through this. If transformations are not applied correctly it is easy to check the generation plan for a model to see if all the generators reducing the abstraction to C have been executed before the \nmodules.gen\n generator. \n\n\nHigher Level Abstractions\n\n\nThe top layer in our example is a language that integrates state-machines and components. Its priorities are only set relative to the two generators it extents: \nmbeddr.statemachines\n and \nmbeddr.components\n. Since these generators itself have priorities that require them to be executed before the \nmodules.gen\n generator is run no additional priorities are required.",
            "title": "Complex Multistage Generators"
        },
        {
            "location": "/Complex/#complex-multistage-generators",
            "text": "When writing large sets of generators and languages that build on top of each other it can be a challenge to understand what is going on during generation. Especially defining generator priorities to order them correctly can get messy quickly. If not taken care of it can happen that a lot of cross generator dependencies are introduces just for the sake of making sure generators are executed in the correct order. A pattern to counter this is to define logical checkpoint/barriers (not to be mistaken with the checkpoints you can define in a generation plan in MPS) in your generator priorities. Priorities are the assigned relative to this barriers. The barriers represent level of abstraction, If a generator requires a certain level of abstraction as input its priorities are defined according to that. It is important a singe generator is picked for each of these barriers to have single point where these dependencies are relative to. This makes debugging much easier. We will use an example from mbeddr below to illustrate this.",
            "title": "Complex Multistage Generators"
        },
        {
            "location": "/Complex/#mbeddr-example",
            "text": "While mbeddr itself uses over 30 generators in total their priorities are in most cases easy to unterstand. Most of the generators are pretty isolated from the point of view and most of them only define that they need to be run before the the  modules.gen  generator. In this example we will look at 3 logical stages of mbeddr all of them on different layers of abstraction.  We will start explaining them from the bottom to the top.",
            "title": "Mbeddr Example"
        },
        {
            "location": "/Complex/#mbeddrmodulesgen-layer",
            "text": "This is the lowest layer of abstractions it assumes that the input is mbeddr C99 representation. This input is basically a simplified version C99 without headers and with some other minor adaptions. This generator transforms its input into  real  C99 code with  .c  and  .h  files. If language extension provides a higher abstraction than this then it defines its generator priorities  relative to this generator. One example here is the  mbeddr.unittest  language.",
            "title": "mbeddr.modules.gen layer"
        },
        {
            "location": "/Complex/#the-middle-layer",
            "text": "This layer contains all sorts of higher level abstractions than C. They are all independent from each other but at some point they need to generate down to mbeddr C. This needs to happen before the  modules.gen  generator is executed because it assumes that the input is C. All of the languages define their priority relative the  modules.gen  generator. Debugging if the order is correct is easy through this. If transformations are not applied correctly it is easy to check the generation plan for a model to see if all the generators reducing the abstraction to C have been executed before the  modules.gen  generator.",
            "title": "The middle layer"
        },
        {
            "location": "/Complex/#higher-level-abstractions",
            "text": "The top layer in our example is a language that integrates state-machines and components. Its priorities are only set relative to the two generators it extents:  mbeddr.statemachines  and  mbeddr.components . Since these generators itself have priorities that require them to be executed before the  modules.gen  generator is run no additional priorities are required.",
            "title": "Higher Level Abstractions"
        },
        {
            "location": "/Multiple_Outputs/",
            "text": "Multiple Outputs from a Single Model\n\n\nIn many cases it is desired to generate multiple independent outputs from the same input model. For example XML descriptions of interfaces, C code for testing implementations of these interfaces and JavaScript that could talk to such implementations from the browser. For reasons of loose coupling it desirable that these three generators could evolve independently. A naive solution might be to copy the in each generator and then reduce it. Since mapping rules are usually written for individual concepts the rule would need to ensure that they only handle nodes that are related to their output. This pollutes the conditions of reduction rule quite quickly and also prevent reuse of generators because they become tightly coupled. It also doesn't solve the problem that the output will all end up in the same \nsource_gen\n folder.\n\n\nGenerator Configuration Pattern\n\n\nA pattern that is proven in use in many projects is to separate generation and \nthe model\n from each other. \nThe model\n contains the actual content that we want to generate and then there are (several) models that only contain a concept specifically introduced to configure the generation. \n\n\n\n\nNote: For instance the mbeddrs \nBuildConfiguration\n is such a concept. While it was not only introduced for this reason it also fulfils this purpose. It can be used to generate tests into a different location than the production code.\n\n\n\n\nThese generations configuration concepts usually contain either a reference to complete model they are supposed to generator or to content of the model that should get generated. This mostly depends on the needs of the users.\n\n\nThe first things that happens during generation is that all the relevant content from \nthe model\n is copied into the currently generated model (the model that only contains the configuration). After that everything in the generator chain works \nas usual\n. And all generators can safely assume that all the content they are handling is supposed to be handled by these rules. There is no need for additional checking, etc.\n\n\nThis also allows to generate different outputs concurrently. As we have a single model per output we want to produce MPS can generate them concurrently, they only require read access to the model with the actual content. \n\n\nThere are different ways such generator configurations could refer to the input to generate:\n\n\n\n\nA reference to a complete model. \nModelRefExpression\n is a handy concept here. \n\n\nA reference to one or more root nodes of the model get generated. If the language supports cross root node references there are two options as well:\n\n\nReferences to the roots nodes the user cares about and the generator will copy the dependencies in regardless if the user specified them. \n\n\nReferences to all root nodes the generator needs for generation need to be specified explicitly. This is often desired in case the generator configuration has more semantics to it then just copying the content. See mbeddr \nBuildConfiguration\n as an example where the order of these elements for instance is the order in which the C compiler will evaluate the files.\n\n\n\n\n\n\n\n\nImplementation\n\n\nWhen implementing such generators there are some things to keep in mind. Instead of using the \nBuildConfiguration\n of mbeddr as an example we are using a very simple excerpt from other generators here:\n\n\nnlist<IConfigItem> configs = model.nodes(IConfigItem); \n\nsequence<node<ConfigRootRef>> refs = configs.rootRefs; \nlist<node<Root>> roots = refs.compChunk.toList; \n\nrefs.forEach({~ref => roots.addAll(ref.collectMissingRoots(roots).toList); }); \n\nnlist<> nodes2copy = new nlist<>; \nnodes2copy.addAll(roots); \n\nnlist<> copies = genContext.copy with trace nodes2copy; \n\nmodel.roots(<all>).forEach({~it => it.detach; }); \n\ncopies.forEach({~it => model.add root(it); });\n\n\n\n\nWhile there is some code to collect the dependencies at first the most important line is: \nnlist<> copies = genContext.copy with trace nodes2copy;\n. This uses the \ncopy with trace\n method of the generation context rather then iterating over the nodes one by one and call \n.copy\n on them. This has one major advantage: MPS will take care of changing the references in the nodes that are copied. This way all references to nodes that are in the list of nodes to be copied are then pointing to the copy. This saves a lot of effort in setting references manually after copying the nodes manually. Because we want the references in the model that we generate to point in that model and not to nodes from the original input. Otherwise we wouldn't be able to use mapping labels to look out the output that ware produced for node during generation.",
            "title": "Multiple Output from a Single Model"
        },
        {
            "location": "/Multiple_Outputs/#multiple-outputs-from-a-single-model",
            "text": "In many cases it is desired to generate multiple independent outputs from the same input model. For example XML descriptions of interfaces, C code for testing implementations of these interfaces and JavaScript that could talk to such implementations from the browser. For reasons of loose coupling it desirable that these three generators could evolve independently. A naive solution might be to copy the in each generator and then reduce it. Since mapping rules are usually written for individual concepts the rule would need to ensure that they only handle nodes that are related to their output. This pollutes the conditions of reduction rule quite quickly and also prevent reuse of generators because they become tightly coupled. It also doesn't solve the problem that the output will all end up in the same  source_gen  folder.",
            "title": "Multiple Outputs from a Single Model"
        },
        {
            "location": "/Multiple_Outputs/#generator-configuration-pattern",
            "text": "A pattern that is proven in use in many projects is to separate generation and  the model  from each other.  The model  contains the actual content that we want to generate and then there are (several) models that only contain a concept specifically introduced to configure the generation.    Note: For instance the mbeddrs  BuildConfiguration  is such a concept. While it was not only introduced for this reason it also fulfils this purpose. It can be used to generate tests into a different location than the production code.   These generations configuration concepts usually contain either a reference to complete model they are supposed to generator or to content of the model that should get generated. This mostly depends on the needs of the users.  The first things that happens during generation is that all the relevant content from  the model  is copied into the currently generated model (the model that only contains the configuration). After that everything in the generator chain works  as usual . And all generators can safely assume that all the content they are handling is supposed to be handled by these rules. There is no need for additional checking, etc.  This also allows to generate different outputs concurrently. As we have a single model per output we want to produce MPS can generate them concurrently, they only require read access to the model with the actual content.   There are different ways such generator configurations could refer to the input to generate:   A reference to a complete model.  ModelRefExpression  is a handy concept here.   A reference to one or more root nodes of the model get generated. If the language supports cross root node references there are two options as well:  References to the roots nodes the user cares about and the generator will copy the dependencies in regardless if the user specified them.   References to all root nodes the generator needs for generation need to be specified explicitly. This is often desired in case the generator configuration has more semantics to it then just copying the content. See mbeddr  BuildConfiguration  as an example where the order of these elements for instance is the order in which the C compiler will evaluate the files.",
            "title": "Generator Configuration Pattern"
        },
        {
            "location": "/Multiple_Outputs/#implementation",
            "text": "When implementing such generators there are some things to keep in mind. Instead of using the  BuildConfiguration  of mbeddr as an example we are using a very simple excerpt from other generators here:  nlist<IConfigItem> configs = model.nodes(IConfigItem); \n\nsequence<node<ConfigRootRef>> refs = configs.rootRefs; \nlist<node<Root>> roots = refs.compChunk.toList; \n\nrefs.forEach({~ref => roots.addAll(ref.collectMissingRoots(roots).toList); }); \n\nnlist<> nodes2copy = new nlist<>; \nnodes2copy.addAll(roots); \n\nnlist<> copies = genContext.copy with trace nodes2copy; \n\nmodel.roots(<all>).forEach({~it => it.detach; }); \n\ncopies.forEach({~it => model.add root(it); });  While there is some code to collect the dependencies at first the most important line is:  nlist<> copies = genContext.copy with trace nodes2copy; . This uses the  copy with trace  method of the generation context rather then iterating over the nodes one by one and call  .copy  on them. This has one major advantage: MPS will take care of changing the references in the nodes that are copied. This way all references to nodes that are in the list of nodes to be copied are then pointing to the copy. This saves a lot of effort in setting references manually after copying the nodes manually. Because we want the references in the model that we generate to point in that model and not to nodes from the original input. Otherwise we wouldn't be able to use mapping labels to look out the output that ware produced for node during generation.",
            "title": "Implementation"
        }
    ]
}